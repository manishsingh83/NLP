{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff22c87",
   "metadata": {},
   "source": [
    "# Hands on POS Taggers Part-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46be89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexicon & Rule + Based + POS-Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f0018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS Tagging- Lexicon and RUle Based Taggers\n",
    "* In the guided exercise, you will explore he WSJ(wall street journel) POS tagged corpus that comes with NLTK and build a lexicon\n",
    "* and rule based tagger using the corpus as the training data.\n",
    "* # This exercise is divided into the following sections:\n",
    "*    1. Reading and understanding and tagged dataset\n",
    "*    2. Exploratory analysis\n",
    "*    3. Lexicon and rule-based model.\n",
    "    * Creating and evaluating a lexicon POS Tagger\n",
    "    * Creating and evaluating a rule based POS Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c60f76",
   "metadata": {},
   "source": [
    "# Reading & Understanding the tagged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45146937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint, time, math\n",
    "from sklearn.model_selection import *\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb490a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('treebank') # download it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a8dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "corpus = list(nltk.corpus.treebank.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7576ed6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NNP'),\n",
       "  ('Vinken', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('61', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('old', 'JJ'),\n",
       "  (',', ','),\n",
       "  ('will', 'MD'),\n",
       "  ('join', 'VB'),\n",
       "  ('the', 'DT'),\n",
       "  ('board', 'NN'),\n",
       "  ('as', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('nonexecutive', 'JJ'),\n",
       "  ('director', 'NN'),\n",
       "  ('Nov.', 'NNP'),\n",
       "  ('29', 'CD'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NNP'),\n",
       "  ('Vinken', 'NNP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('chairman', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Elsevier', 'NNP'),\n",
       "  ('N.V.', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('the', 'DT'),\n",
       "  ('Dutch', 'NNP'),\n",
       "  ('publishing', 'VBG'),\n",
       "  ('group', 'NN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# samples: Each senteces is a list of (word, pos) tuples\n",
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba5cc394",
   "metadata": {},
   "source": [
    "In the list mentioned above, each element of the list is a sentences. Also, note that each sentences ends with a full stop'.'\n",
    "whose POS tag is also a thus the POS demarcates the end of a sentence.\n",
    "Also, we do not need the corpus to be segmented  into sentences but can rather use a list of (word, tag) tuples. let's convert the list into a (word, tag) tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09b734d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('chairman', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Elsevier', 'NNP'),\n",
       " ('N.V.', 'NNP'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('Dutch', 'NNP'),\n",
       " ('publishing', 'VBG'),\n",
       " ('group', 'NN')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list of sents to a list of (word, pos tag) tuples\n",
    "tagged_words = [tup for sent in corpus for tup in sent]\n",
    "print(len(tagged_words))\n",
    "tagged_words[:30]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75dcafc6",
   "metadata": {},
   "source": [
    "we now have a list of about 100676 (word, tag) tuples. let's now do some exploratory analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e76d6a4",
   "metadata": {},
   "source": [
    "# HANDS ON POS-TAGGERS PART-2\n",
    "\n",
    "** 2. Exploratory Analysis\n",
    "*let's now conduct some basic exploratory analysis to understand the tagged corpus. to start with let's ask some\n",
    "* # simple questions\n",
    "*1. how many unique tags are there in the corpus?\n",
    "*2. which is the most frequent tag in the corpus?\n",
    "*3. which tag is most commonly assigned to the follwing words:\n",
    "    * 'bank'\n",
    "    * 'executed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6ddb798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the number of unique POS tags in the corpus\n",
    "# you can use the set() function on the list of tags to get a unique set of tags\n",
    "# and compute its length\n",
    "tags = [pairs[1] for pairs in tagged_words]\n",
    "unique_tags = set(tags)\n",
    "len(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51e1d688",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'NNP': 9410,\n",
       "         ',': 4886,\n",
       "         'CD': 3546,\n",
       "         'NNS': 6047,\n",
       "         'JJ': 5834,\n",
       "         'MD': 927,\n",
       "         'VB': 2554,\n",
       "         'DT': 8165,\n",
       "         'NN': 13166,\n",
       "         'IN': 9857,\n",
       "         '.': 3874,\n",
       "         'VBZ': 2125,\n",
       "         'VBG': 1460,\n",
       "         'CC': 2265,\n",
       "         'VBD': 3043,\n",
       "         'VBN': 2134,\n",
       "         '-NONE-': 6592,\n",
       "         'RB': 2822,\n",
       "         'TO': 2179,\n",
       "         'PRP': 1716,\n",
       "         'RBR': 136,\n",
       "         'WDT': 445,\n",
       "         'VBP': 1321,\n",
       "         'RP': 216,\n",
       "         'PRP$': 766,\n",
       "         'JJS': 182,\n",
       "         'POS': 824,\n",
       "         '``': 712,\n",
       "         'EX': 88,\n",
       "         \"''\": 694,\n",
       "         'WP': 241,\n",
       "         ':': 563,\n",
       "         'JJR': 381,\n",
       "         'WRB': 178,\n",
       "         '$': 724,\n",
       "         'NNPS': 244,\n",
       "         'WP$': 14,\n",
       "         '-LRB-': 120,\n",
       "         '-RRB-': 126,\n",
       "         'PDT': 27,\n",
       "         'RBS': 35,\n",
       "         'FW': 4,\n",
       "         'UH': 3,\n",
       "         'SYM': 1,\n",
       "         'LS': 13,\n",
       "         '#': 16})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which is the most frequent tag in the corpus to count the frequency of elements in a list, \n",
    "#  the Counter() class from collection\n",
    "# module is very useful, as shown below\n",
    "\n",
    "from collections import Counter\n",
    "tag_counts = Counter(tags)\n",
    "tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8f61a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 13166),\n",
       " ('IN', 9857),\n",
       " ('NNP', 9410),\n",
       " ('DT', 8165),\n",
       " ('-NONE-', 6592),\n",
       " ('NNS', 6047),\n",
       " ('JJ', 5834),\n",
       " (',', 4886)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the most commen tags can be seen using the most_common() method of Counter\n",
    "tag_counts.most_common(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bdf2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thus NN is the most common tag follwed by IN, NNP, DT, None. etc You can read the exhaustive list of tags using the \n",
    "#  NLTK documentation as shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d415e9d",
   "metadata": {},
   "source": [
    "# Hands ON POS-Taggers Part-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5284d1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping help\\tagsets.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1dbbb867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "# list of POS tags in NLTK\n",
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61b9a021",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bank', 'NN'),\n",
       " ('Bank', 'NNP'),\n",
       " ('bank', 'NN'),\n",
       " ('Bank', 'NNP'),\n",
       " ('bank', 'NN'),\n",
       " ('Bank', 'NNP'),\n",
       " ('bank', 'NN'),\n",
       " ('Bank', 'NNP'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('bank', 'NN'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('bank', 'NN'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('Bank', 'NNP'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('Bank', 'NNP'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('bank', 'NN'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('Bank', 'NNP'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('Bank', 'NNP'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('Bank', 'NNP'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('bank', 'NN'),\n",
       " ('Bank', 'NNP'),\n",
       " ('bank', 'NN')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which tag is most commonly assigned to the word w\n",
    "bank = [pair for pair in tagged_words if pair[0].lower()== 'bank']\n",
    "bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b10210b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('executive', 'NN'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'JJ'),\n",
       " ('executive', 'NN'),\n",
       " ('executive', 'JJ')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which tag is most commonly assigned to the word w.\n",
    "executive = [pair for pair in tagged_words if pair[0].lower() == 'executive']\n",
    "executive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d335ed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9972602739726028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('publishing', 'VBG'),\n",
       " ('causing', 'VBG'),\n",
       " ('using', 'VBG'),\n",
       " ('talking', 'VBG'),\n",
       " ('having', 'VBG'),\n",
       " ('making', 'VBG'),\n",
       " ('surviving', 'VBG'),\n",
       " ('including', 'VBG'),\n",
       " ('including', 'VBG'),\n",
       " ('according', 'VBG'),\n",
       " ('remaining', 'VBG'),\n",
       " ('according', 'VBG'),\n",
       " ('declining', 'VBG'),\n",
       " ('rising', 'VBG'),\n",
       " ('yielding', 'VBG'),\n",
       " ('waiving', 'VBG'),\n",
       " ('holding', 'VBG'),\n",
       " ('holding', 'VBG'),\n",
       " ('cutting', 'VBG'),\n",
       " ('manufacturing', 'VBG')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many words with the tag 'VBG' end with 'ing'\n",
    "participle_verbs = [pair for pair in tagged_words if pair[1] == 'VBG']  # VBG = verb, present participle or gerund\n",
    "ing_verbs = [pair for pair in participle_verbs if pair[0].endswith('ing')]\n",
    "print(len(ing_verbs) / len(participle_verbs))\n",
    "ing_verbs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d889521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3881038448899113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('reported', 'VBD'),\n",
       " ('stopped', 'VBD'),\n",
       " ('studied', 'VBD'),\n",
       " ('led', 'VBD'),\n",
       " ('worked', 'VBD'),\n",
       " ('explained', 'VBD'),\n",
       " ('imposed', 'VBD'),\n",
       " ('dumped', 'VBD'),\n",
       " ('poured', 'VBD'),\n",
       " ('mixed', 'VBD'),\n",
       " ('described', 'VBD'),\n",
       " ('ventilated', 'VBD'),\n",
       " ('contracted', 'VBD'),\n",
       " ('continued', 'VBD'),\n",
       " ('eased', 'VBD'),\n",
       " ('ended', 'VBD'),\n",
       " ('lengthened', 'VBD'),\n",
       " ('reached', 'VBD'),\n",
       " ('resigned', 'VBD'),\n",
       " ('approved', 'VBD')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many words with the tag 'VBD' (verb, past tense) end with 'ed'\n",
    "past_tense_verbs = [pair for pair in tagged_words if pair[1] == 'VBD'] # VBD = verb, past tense\n",
    "ed_verbs = [pair for pair in past_tense_verbs if pair[0].endswith('ed')]\n",
    "print(len(ed_verbs) / len(past_tense_verbs))\n",
    "ed_verbs[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4bd3f6",
   "metadata": {},
   "source": [
    "# Hands on POS-Taggers Part-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42654184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5834\n",
      "2611\n",
      "0.4475488515598217\n"
     ]
    }
   ],
   "source": [
    "# what fraction of adjective JJ are follwed by a noun NN\n",
    "# create a list of all tags (without the words)\n",
    "tags = [pair[1] for pair in tagged_words]\n",
    "\n",
    "# create a list of JJ tags\n",
    "jj_tags = [t for t in tags if t == 'JJ']\n",
    "\n",
    "# create a list of (JJ, NN) tags\n",
    "jj_nn_tags = [(t, tags[index+1]) for index, t in enumerate(tags)\n",
    "             if t=='JJ' and tags[index+1]=='NN']\n",
    "\n",
    "print(len(jj_tags))\n",
    "print(len(jj_nn_tags))\n",
    "print(len(jj_nn_tags) / len(jj_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04094bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8165\n",
      "3844\n",
      "0.470789957134109\n"
     ]
    }
   ],
   "source": [
    "# What fraction of determiners DT are followed by a noun NN\n",
    "dt_tags = [t for t in tags if t == 'DT']\n",
    "dt_nn_tags = [(t, tags[index+1]) for index, t in enumerate(tags)\n",
    "             if t=='DT' and tags[index+1] == 'NN']\n",
    "\n",
    "print(len(dt_tags))\n",
    "print(len(dt_nn_tags))\n",
    "print(len(dt_nn_tags) / len(dt_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8e4f5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927\n",
      "756\n",
      "0.8155339805825242\n"
     ]
    }
   ],
   "source": [
    "# What fraction of modals MD are followed by a verb VB\n",
    "md_tags = [t for t in tags if t == 'MD']\n",
    "md_vb_tags = [(t, tags[index+1]) for index, t in enumerate(tags)\n",
    "             if t=='MD' and tags[index+1] == 'VB']\n",
    "\n",
    "print(len(md_tags))\n",
    "print(len(md_vb_tags))\n",
    "print(len(md_vb_tags) / len(md_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fcdabb",
   "metadata": {},
   "source": [
    "# Hands on POS-Taggers Part-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cce44d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexicon and Rule-Based Models for POS Tagging\n",
    "* Let's now see lexicon and rule based models for POS tagging. we'll first split the corpus into training and\n",
    "# test set and then use built in NLTK tagger\n",
    "# * Splitting into Train & Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e27221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2739\n",
      "1175\n",
      "[[('Georgia', 'NNP'), ('Gulf', 'NNP'), ('rebuffed', 'VBD'), ('that', 'DT'), ('offer', 'NN'), ('in', 'IN'), ('September', 'NNP'), ('and', 'CC'), ('said', 'VBD'), ('0', '-NONE-'), ('it', 'PRP'), ('would', 'MD'), ('study', 'VB'), ('other', 'JJ'), ('alternatives', 'NNS'), ('.', '.')], [('Olympia', 'NNP'), ('Broadcasting', 'NNP'), ('Corp.', 'NNP'), ('said', 'VBD'), ('0', '-NONE-'), ('it', 'PRP'), ('did', 'VBD'), (\"n't\", 'RB'), ('make', 'VB'), ('a', 'DT'), ('$', '$'), ('1.64', 'CD'), ('million', 'CD'), ('*U*', '-NONE-'), ('semiannual', 'JJ'), ('interest', 'NN'), ('payment', 'NN'), ('due', 'JJ'), ('yesterday', 'NN'), ('on', 'IN'), ('$', '$'), ('23.4', 'CD'), ('million', 'CD'), ('*U*', '-NONE-'), ('of', 'IN'), ('senior', 'JJ'), ('subordinated', 'VBN'), ('debentures', 'NNS'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# splitting into train & test\n",
    "import random\n",
    "random.seed(1234)\n",
    "train_set, test_set = train_test_split(corpus, test_size= 0.3)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(train_set[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a1b5d",
   "metadata": {},
   "source": [
    "# 3.2 Lexicon (Unigram) Tagger\n",
    "* Let's now try training a lexicon(or a unigram ) tagger which assigns the most commonly assigned tag to a word\n",
    "* In NLTK, the UnigramTagger() can be used to train such a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0027e01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_12452\\2289405898.py:3: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  unigram_tagger.evaluate(test_set)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8718476241040616"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lexicon\n",
    "unigram_tagger = nltk.UnigramTagger(train_set)\n",
    "unigram_tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3933322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Even a simple unigram tagger seems to perform fairly well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b11f01",
   "metadata": {},
   "source": [
    "# 3.3 Rule-Based(regular expression)\n",
    "* Now let's build a rule-based, or regule expression based tagger. In NLTK the RegexpTagger( can be provided with handwritten\n",
    "* regular expression patterns, as shown below\n",
    "* In the example below we specify regexes for gerunds and past tense verbs ( as seen above) 3rd singular present verb \n",
    "* # ( creates, moves, makes etc), model verbs MD (should,would,could), possesion noun (partner's, bank's, etc) plural nouns\n",
    "* # (banks, intitutions), cardinal numbers CD and finally, if none of the above rules are applicable to a word we tag the most *# frewuent tag NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "571f88c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging , # example from the NLTK book\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'),   # gerund\n",
    "    (r'.*ed$', 'VBD' ),   # past tense\n",
    "    (r'.*es$', 'VBZ'),    # 3rd singuler present \n",
    "    (r'.*ould$', 'MD'),    # models\n",
    "    (r\".*\\'s$\", 'NN$'),    # possessive nouns\n",
    "    (r'.*s$', 'NNS'),    # plural nouns\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD' ),   # cardinal numbers\n",
    "    (r'.*', 'NN')       # nouns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e32594d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "# help (regexp_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a78d91d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_12452\\792752471.py:1: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  regexp_tagger.evaluate(test_set)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22083222723652773"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc96db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combination Taggers\n",
    "* Let's now try combining the Taggers created above\n",
    "However, if we could combine the lexicon and the rule-based tagger. \n",
    "we can potentialy create atagger much better than any of the individual ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6983a4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_12452\\2535250660.py:7: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  lexicon_tagger.evaluate(test_set)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9050637111760022"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)\n",
    "\n",
    "# lexicon backed up by the rule-based tagger\n",
    "lexicon_tagger = nltk.UnigramTagger(train_set, backoff=rule_based_tagger)\n",
    "\n",
    "lexicon_tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b8a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c975b269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8351b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
